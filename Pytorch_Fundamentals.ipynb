{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7bbG8lic1Karouda/fpNR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MFaiqKhan/PyTorch_colab/blob/main/Pytorch_Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 00. PyTorch Fundamentals::\n",
        "\n",
        "Resources Notebook : https://www.learnpytorch.io/00_pytorch_fundamental"
      ],
      "metadata": {
        "id": "XvPAduQK-bGC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRQLM3is6-1A",
        "outputId": "1616f62d-5df2-4cf6-983e-839c1b102cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello I am learning Machine Learning and Deep Learning\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello I am learning Machine Learning and Deep Learning\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__) # built in attr of pytorch modle that contains the version number of the Library\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6DcnJA-A0VW",
        "outputId": "c30d510f-9b2c-4f44-9af0-4ce15946b248"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction to Tensors:\n",
        "\n",
        "### Creating Tensors\n",
        "\n",
        "PyTorch tensors are created using `torch.Tensor()` \n",
        "\n",
        "Usually Scalar and Vector Tensors are represented by Lower case a and y Respectively.\n",
        "\n",
        "Matric and Tensor are represented by Upper case Q and X Respectively"
      ],
      "metadata": {
        "id": "Hak3-bV6Il4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scalar:\n",
        "\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9C03AYTIs1H",
        "outputId": "933bb65b-928b-4f70-95d3-86a2e709664e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0qVQ7suPgmz",
        "outputId": "b42056dc-2980-486b-cbb1-0a9cedbdae8a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Tensor Back from as Python int\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv2_jYvTPlfx",
        "outputId": "15627f98-4d42-451c-a0be-a80003eab64b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector\n",
        "\n",
        "vector = torch.tensor([7,7,7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAn65TFqQqs8",
        "outputId": "48193985-3874-48f0-dd74-64fe415a7666"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j87vmGz3Q6ah",
        "outputId": "5a8a22ac-34f6-4cd3-89c1-028ad09d7c02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-vVjcTxgwV5",
        "outputId": "0f184703-4cc0-4f20-b405-58332169a75a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MATRIX\n",
        "\n",
        "MATRIX = torch.tensor([[1,8],\n",
        "                       [1,3]])\n",
        "MATRIX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncj5DtQFgzJ-",
        "outputId": "9850816d-f38e-4490-a691-4b019f7b2142"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 8],\n",
              "        [1, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_Pvh17Lk7ph",
        "outputId": "1ab4d2a0-2c35-4513-ba3f-29236cff2d93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy18lpH6lAJG",
        "outputId": "18e53d9c-f6d7-4cef-db5c-f5243fac9303"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjkdCnTSl3x9",
        "outputId": "404d2a57-9c68-4f23-cdd0-abd3788e7ff2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                        [9,2,3],\n",
        "                        [2,3,2]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BThhwXSeWUN_",
        "outputId": "8d1d8748-628b-404d-e81f-8adfc8516b0d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [9, 2, 3],\n",
              "         [2, 3, 2]]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdphFgyXWqRG",
        "outputId": "baaac07b-8fa5-4324-9b5b-4dcd689d397c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape # Outer Bracket Contains only 1 cell, middle inner bracket contrains 3 brackets inside, and inner most bracket contains\n",
        "# 3 elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYWNcsyPWzIA",
        "outputId": "ff721b17-f12c-4b69-a65c-5f9e76b855ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0][0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v75Q89ToXUe2",
        "outputId": "88872174-e4c0-405a-9e35-06e3940c9e0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Random Tensors:\n",
        "\n",
        "random_tensor = torch.rand(4,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5orTfYCWjMB5",
        "outputId": "d451247c-ac43-44bf-e34a-34f4d22cec28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7367, 0.2587, 0.7154, 0.8073],\n",
              "        [0.3345, 0.8894, 0.6014, 0.3908],\n",
              "        [0.6791, 0.5267, 0.6967, 0.2094],\n",
              "        [0.5966, 0.2157, 0.4252, 0.9778]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### random tensor with similar shape to an image\n",
        "\n",
        "random_image_tensor = torch.rand(size=(3,224,224)) # color channels, height, width\n",
        "random_image_tensor.shape, random_image_tensor.ndim "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXePAvqGmEAZ",
        "outputId": "18307823-b4c0-418e-dce0-cd0d91f5c5bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 224, 224]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Zeroes and Ones in Tensor Representation:\n",
        "\n",
        "zeros = torch.zeros(size=(4,4))\n",
        "zeros, zeros.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCTa1UGio4RS",
        "outputId": "5a8a77f6-06b4-4f9f-b87a-9170035202e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros * random_tensor ## size/shape of both zeros and random_tensor must be equal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieke8_Rxo9BY",
        "outputId": "e8e1881a-74a1-4f1e-fc95-ca03a1209479"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(size=(4,4))\n",
        "ones, ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkouNkc-pqGM",
        "outputId": "bbf4bdfa-7ac4-432a-fd09-61dda99c1256"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Range of Tensors and tensors-like\n",
        "\n",
        "one_to_ten = torch.arange(start=0, end=100, step=7)\n",
        "one_to_ten, one_to_ten.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79YvYMFWp42i",
        "outputId": "302e7c64-ef79-4683-ed3b-38507f2785b4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0,  7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 91, 98]),\n",
              " torch.Size([15]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ten_zeros = torch.zeros_like(input=one_to_ten) # a tensor of all zeros with the same shape as a previous tensor.\n",
        "ten_zeros\n",
        "# Sometimes you might want one tensor of a certain type with the same shape as another tensor."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFqNqXLXvbTa",
        "outputId": "e10dad9b-9380-4f5b-95a8-9e524837a9c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Datatypes\n",
        "\n",
        "generally the default and most common is 32 bit floating point.\n",
        "\n",
        "there are different different type of tensor datatypes: https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "The reason for all of these is to do with precision in computing.\n",
        "Precision is the amount of detail used to describe a number.\n",
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "<b/>Note</b>: Tensor Datatypes is one of the 3 big errors you will find or run into with pytorch and deeplearning.\n",
        "\n",
        "(for computing purpose both tensors should be similar to each other on 3 things)\n",
        "\n",
        "1.) Tensors not right datatype\n",
        "\n",
        "2.) tensors not right shape\n",
        "\n",
        "3.) not on right device\n",
        " "
      ],
      "metadata": {
        "id": "vZMynDkhzSWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### float 32 tensor/default\n",
        "\n",
        "default_tensor = torch.tensor([3, 6.0, 9.0],\n",
        "                                dtype = None,\n",
        "                                device=None,\n",
        "                                requires_grad=False)\n",
        "\n",
        "default_tensor, default_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGMqhxjaz4hx",
        "outputId": "1574c82c-fb24-4ec5-eaa2-ae87bbf8ce4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([3., 6., 9.]), torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Convert it into 64 bit floating point\n",
        "\n",
        "float_64 = default_tensor.type(torch.float64)\n",
        "float_64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1JtNyR_1Nay",
        "outputId": "b0c1d6e8-8a56-4934-e279-deecb4a589fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Can two datatypes of tensor float 16 and 32 respectively be multiplied together ?\n",
        "\n",
        "float_64 * default_tensor  ## Yes they can , but in neural networks and in some places they will bring error , so we should \n",
        "# use same datatypes \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJfc42kE8rNY",
        "outputId": "cd60cea8-1b65-41bd-a383-a171be7f4c5a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### lets do for two different Int datatypes of tensors \n",
        "\n",
        "int_32_tensor = torch.tensor([1,2,3], dtype=torch.int32)\n",
        "int_32_tensor * float_64 ## It works as well, so sometimes error do occur in neaural network rather than normal multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si53U-gl9DNv",
        "outputId": "714a3b23-9abc-4878-f388-cec21412f43f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3., 12., 27.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting Information from Tensors(Tensors Attributes)\n",
        "\n",
        "1.) Tensors not right datatype, use `tensor.dtype` to get datatype of a tensor\n",
        " \n",
        "2.) tensors not right shape, use `tensor.shape` to get shape\n",
        " \n",
        "3.) not on right device, use `tensor.device` to get device "
      ],
      "metadata": {
        "id": "QBYhMkc7-k_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### create a tensor:\n",
        "\n",
        "new_tensor = torch.rand(2,2)\n",
        "new_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyN5it8GAz_g",
        "outputId": "2d8271cb-5c5c-4786-ce51-0b818a07e42e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7505, 0.7626],\n",
              "        [0.0953, 0.1231]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the details of the new_tensor we created above\n",
        "\n",
        "print(new_tensor)\n",
        "print(f\"Dataype of tensor: {new_tensor.dtype}\") ## An f-string is a string literal that allows you to include expressions inside braces {} \n",
        "# which are evaluated at runtime and replaced with their values as a part of the string. \n",
        "# This is a convenient way to construct strings that contain variables or other expressions in a concise and readable way.\n",
        "print(f\"Shape of tensor: {new_tensor.shape}\") \n",
        "print(f\"Device of tensor: {new_tensor.device}\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysIqJNaABAaK",
        "outputId": "e59a2d80-8291-40b0-9c03-df23f842744c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7505, 0.7626],\n",
            "        [0.0953, 0.1231]])\n",
            "Dataype of tensor: torch.float32\n",
            "Shape of tensor: torch.Size([2, 2])\n",
            "Device of tensor: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors (Tensor Operations)\n",
        "\n",
        "Commonly used Tensor Operations to create a neaural network : \n",
        "- Addition\n",
        "- Subtraction\n",
        "- Multiplication (element-wise) (Multiple a matrix by a single number)\n",
        "- Division\n",
        "- Matrix Multiplication"
      ],
      "metadata": {
        "id": "rjNeRbqlZvjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 10 to a tensor.\n",
        "tensor = torch.tensor([2,4,5])\n",
        "tensor + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxjozLU-hL6q",
        "outputId": "40ec56f1-09fc-4d35-befe-d0c52acb2a86"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12, 14, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply tensor by 10\n",
        "\n",
        "multiply_tensor = tensor * 10\n",
        "multiply_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ueqoVIAiV5o",
        "outputId": "c91ef2c9-9158-490f-9561-f23cc304c175"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([20, 40, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor ## It is still the same tensor we initialized above, "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCX2_fBOisje",
        "outputId": "62c6f3f4-31f0-4866-b78b-eae9b819a157"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subtract 10\n",
        "\n",
        "tensor - 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpBUVzkTi-Pz",
        "outputId": "9786db93-a959-4864-de73-2f21d2eb3399"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-8, -6, -5])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch in-built functions\n",
        "torch.mul(tensor, 10), torch.add(tensor,10) # (Short for Multiplication etc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94Z4yqizjUNT",
        "outputId": "ce9d6df7-59c8-43c1-b8c2-649715bf76ac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([20, 40, 50]), tensor([12, 14, 15]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication in neural networks and deep learning:\n",
        "\n",
        "- Element Wise Multiplication\n",
        "- Multiplying One Matric with another Matric (Dot Product)\n",
        "\n",
        "How to do Matrix Multiplication : https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "\n",
        "Two Main Rules that for Matrix Multiplication : \n",
        "1. The **inner Dimensions** Must Match: (Column of first one should match the row of second one)\n",
        "* `(3, 2) @ (3, 2)` won't work\n",
        "\n",
        "* `(2, 3) @ (3, 2)` will work\n",
        "\n",
        "* `(3, 2) @ (2, 3)` will work\n",
        "\n",
        "2. The resulting matrix has the shape of the outer dimensions:\n",
        "\n",
        "* `(2, 3) @ (3, 2) -> (2, 2)`\n",
        "\n",
        "* `(3, 2) @ (2, 3) -> (3, 3)`\n",
        "\n",
        "### Visualize Matric Multiplication by creating your own:\n",
        "http://matrixmultiplication.xyz/"
      ],
      "metadata": {
        "id": "XRI3YlupuH-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @ symbol is another way to multiply matrices same as torch.matmul\n",
        "\n",
        "tensor @ tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPM1i1rc2LQm",
        "outputId": "8dd24db5-5029-4b8d-b686-2176379c473f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(45)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element Wise Multiplication:\n",
        "\n",
        "print(tensor, '*', tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NkbEGCbwPMU",
        "outputId": "64837861-f55f-468b-d49b-f5b0fb4a394e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 4, 5]) * tensor([2, 4, 5])\n",
            "Equals: tensor([ 4, 16, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix Multiplcation :\n",
        "torch.matmul(tensor, tensor) # applying the matrix by matrix rule of multiply and add both."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy_GIVJByJHJ",
        "outputId": "9f8e0ea1-a1b0-4958-9165-fe4519d6e375"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(45)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication by Hand\n",
        "2*2 + 4*4 + 5*5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNriObNSyYaR",
        "outputId": "c202a9fd-1508-4b23-c0d4-48401390771c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time \n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "print(value) # multiplying matrix through forloop, will take longer time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQf8t0ihztZq",
        "outputId": "a826e3ca-d745-49dc-b8c2-48fb99e99769"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(45)\n",
            "CPU times: user 2.01 ms, sys: 0 ns, total: 2.01 ms\n",
            "Wall time: 2.02 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "torch.matmul(tensor,tensor) # built-in version of torch multiplication is optimized , we should always use this rather than by hand"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djqz6gejz1_C",
        "outputId": "8b0f4301-d9db-41f6-e7d2-c16f13734515"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 914 µs, sys: 0 ns, total: 914 µs\n",
            "Wall time: 928 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(45)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One of the most Commmon Errors in Deep Learning: Shape Errors"
      ],
      "metadata": {
        "id": "z0-VH66X0uyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z7l6KSl-97Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape For Matrix Multiplication:\n",
        "tensor1 = torch.tensor([[1,2,1],\n",
        "                        [0,1,0],\n",
        "                        [1,3,4]])\n",
        "\n",
        "tensor2 = torch.tensor([[2,5],\n",
        "                        [6,7],\n",
        "                        [1,8]])\n",
        "\n",
        "torch.matmul(tensor1, tensor2), tensor1.shape, tensor2.shape\n",
        "# torch.mm(tensor1, tensor2) # torch.mm is the same as torch.matmul (It's and Alias for torch.matmul)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKe-S9qS91xW",
        "outputId": "9a3a8610-95bb-42e2-ea7c-ba4f83ba8c50"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[15, 27],\n",
              "         [ 6,  7],\n",
              "         [24, 58]]), torch.Size([3, 3]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do one for the error:\n",
        "tensorA = torch.tensor([[1,2],\n",
        "                        [0,1],\n",
        "                        [1,3]])\n",
        "\n",
        "tensorB = torch.tensor([[2,5],\n",
        "                        [6,7],\n",
        "                        [1,8]])\n",
        "\n",
        "torch.mm(tensorA, tensorB) # Will return an Error"
      ],
      "metadata": {
        "id": "NSdCQP3o-Cng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "213a7843-7bbb-46ff-da2c-b2dbc9d37e82"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e6786680d208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                         [1,8]])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Will return an Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensorA.shape, tensorB.shape # Rule 1 is not followed here, thats why the above code gave us an error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z47g5vg-trK",
        "outputId": "cf138fd4-a786-494b-dc62-98e6ba7d9457"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets change the shape of the tensor B by arranging it applying tranpose function on it.\n",
        "# Transpose  (switch the dimensions of a given tensor)\n",
        "\n",
        "tensorB.T, tensorB.T.shape # rows into column and vice versa "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqY4ryK1-9ON",
        "outputId": "d897f1ac-9144-4278-959d-ac6fbf5a1bdf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[2, 6, 1],\n",
              "         [5, 7, 8]]), torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(tensorA, tensorB.T), torch.matmul(tensorA, tensorB.T).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrmD8iAG_a8m",
        "outputId": "cfdbfe25-54d1-48b2-de62-e2d59e02550c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[12, 20, 17],\n",
              "         [ 5,  7,  8],\n",
              "         [17, 27, 25]]), torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensorA = {tensorA.shape}, tensorB = {tensorB.shape}\\n\")\n",
        "print(f\"New shapes: tensorA = {tensorA.shape} (same as above), tensorB.T = {tensorB.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensorA.shape} * {tensorB.T.shape} <- inner dimensions match\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensorA, tensorB.T)\n",
        "print(output) \n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhskZsSfAfGN",
        "outputId": "d82dd29a-deba-4ece-971c-49bbe735b9a2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensorA = torch.Size([3, 2]), tensorB = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensorA = torch.Size([3, 2]) (same as above), tensorB.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[12, 20, 17],\n",
            "        [ 5,  7,  8],\n",
            "        [17, 27, 25]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor Aggregation ( Finding the min, max, mean, sum etc )\n",
        "\n",
        "Performing a calculation on whole tensor to find a certain/specfic value"
      ],
      "metadata": {
        "id": "E8qpu8XKDbcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor with range:\n",
        "\n",
        "tens = torch.arange(start=0, end=100, step=10)\n",
        "tens, tens.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1Uib7OiEaec",
        "outputId": "57777a85-5fdf-438a-8aca-313656d1824a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the min value in above tensor:\n",
        "\n",
        "torch.min(tens), tens.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b57FaZiFXC1",
        "outputId": "d8b96f03-912a-487b-ed0d-736a9385ad13"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find max value:\n",
        "\n",
        "torch.max(tens), tens.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXnqv55jFzXn",
        "outputId": "6e894e19-c57a-4280-e932-4097b4a52837"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the Mean:\n",
        "\n",
        "torch.mean(tens) # not the right datatype error\n",
        "# the input dtype is int64 which is basically long \n",
        "# and the mean() function uses floating point or complex dtype."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "FJWec7xWF1tK",
        "outputId": "358cdd8d-6c36-4e2b-9a7d-90f5b9a13ba4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-723d0bf105c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Find the Mean:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not the right datatype error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# the input dtype is int64 which is basically long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets convert the dtype of tensor from int64 into float32\n",
        "\n",
        "torch.mean(tens.type(torch.float32)), tens.type(torch.float32).mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgP9ZSf4GT72",
        "outputId": "8ede0637-4031-4e34-ce35-9612513de87d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the Sum:\n",
        "\n",
        "torch.sum(tens), tens.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Kc5-2tvG_4Y",
        "outputId": "b66926a3-97a8-4781-ff72-980c562d4f54"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the Positional Min and Max:"
      ],
      "metadata": {
        "id": "Hhph_Hj5HjnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BLWSvsaHp98",
        "outputId": "ee55bcd5-3273-4f3d-995a-ce9891d28a11"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Index where max value occurs: {tens.argmax()}\")\n",
        "print(f\"Index where min value occurs: {tens.argmin()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGw9uzn0HsTY",
        "outputId": "9302017d-c0ee-4479-8115-1288ea82e0f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index where max value occurs: 9\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshaping, Stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape, `torch.reshape(input, shape)`\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape() link: [Torch.RESHAPE](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape)\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memoery as the original tensor\n",
        "* Stacking - Combine multiple tensors on top of each other (vstack) or side by side (hstack) , `torch.stack(tensors, dim=0)`\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
        "link:[Torch.stack](https://pytorch.org/docs/1.9.1/generated/torch.stack.html)\n",
        "link:[torch.vstack](https://pytorch.org/docs/1.9.1/generated/torch.vstack.html?highlight=torch%20vstack#torch.vstack)\n",
        "link:[torch.hstack](https://pytorch.org/docs/1.9.1/generated/torch.hstack.html?highlight=torch%20hstack#torch.hstack)\n",
        "\n",
        "* Squeeze - remove all `1` dimensions from a tensor\n",
        "* Unsqueeze - add a `1` dimension to a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way."
      ],
      "metadata": {
        "id": "a1k7jqgdpE-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor to manipulate:\n",
        "\n",
        "import torch\n",
        "x = torch.arange(1.,10.)\n",
        "x,x.shape,x.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTto4Cd3sqJp",
        "outputId": "96a58cbb-a61f-4c73-9907-14b4b246aec7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "y = x.reshape(1,9) # the shape should be compatible with the previous shape, otherwise it will give error\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk5irKkovx9r",
        "outputId": "24707e50-4f99-4582-a1f0-dff99e407347"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape, y.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUfshFJ7wIGk",
        "outputId": "477d3065-8da5-412e-aef1-136c0446a4bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 9]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.reshape(9,1)\n",
        "y, y.shape, y.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-3iycbnxDM_",
        "outputId": "e7cd33a5-701a-4fbe-d6e2-0b7a2b5440b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]), torch.Size([9, 1]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view, using view , basically view works same as reshape but it shares the same memory as the original tensor variable\n",
        "\n",
        "z = x.view(1,9)\n",
        "z, z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88cuG4q3xqqF",
        "outputId": "14767464-5b98-4997-e5f5-ea2ac5df042e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# changing z changes xz (because a view of a tensor shares the same memory as the original)\n",
        "\n",
        "z[:,0] = 5 # The colon : before the comma , indicates that we want to select all rows of z, \n",
        "# while the 0 after the comma , indicates that we want to select only the elements in the first column.\n",
        "z,x"
      ],
      "metadata": {
        "id": "hVWJFx_B3q-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed418859-0554-4d50-920d-21c9eb2074a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, when working with two-dimensional arrays, the notation `z[:, 0]` is used to select all the elements in the first column of the array z.\n",
        "\n",
        "The colon `:` before the comma `,` indicates that we want to select all rows of z, while the 0 after the comma `,` indicates that we want to select only the elements in the first column.\n",
        "\n",
        "Here's an example:\n",
        "\n",
        "\n",
        "```\n",
        "import torch\n",
        "\n",
        "z = torch.tensor([[1, 2, 3],\n",
        "                  [4, 5, 6],\n",
        "                  [7, 8, 9]])\n",
        "\n",
        "first_column = z[:, 0]\n",
        "\n",
        "print(first_column)\n",
        "```\n",
        "\n",
        "Output:\n",
        "\n",
        "`tensor([1, 4, 7])`\n",
        "\n",
        "In this example, z is a PyTorch tensor with 3 rows and 3 columns. When we run z`[:, 0]`, we are selecting all the elements in the first column of z, which are `[1, 4, 7]`.\n",
        "\n",
        "The resulting first_column tensor contains the values of all elements in the first column of z. We can see this in the output, where we get a one-dimensional tensor with the values `[1, 4, 7]`.\n",
        "\n",
        "Note that the resulting tensor has a different shape than the original z tensor. z had a shape of (3, 3) while first_column has a shape of (3,), which is a one-dimensional tensor with 3 elements. This is because we are selecting only one column of the original two-dimensional array."
      ],
      "metadata": {
        "id": "a_CqeRxX7VIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.stack \n",
        "\n",
        "x_stacked = torch.stack([x,x], dim=0)\n",
        "x_stacked"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seY3jzW0CVPQ",
        "outputId": "1a2c89ff-2db1-4d9c-9b6c-c2320b8376a9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.stack() is a PyTorch function that concatenates a sequence of tensors along a new dimension, which is added to the resulting tensor. It takes a sequence of tensors as input and returns a new tensor that contains all the input tensors stacked along the specified dimension.\n",
        "\n",
        "The torch.stack() function has two main variants:\n",
        "\n",
        "torch.stack(tensors, dim=0): Stacks the input tensors along a new dimension with the given dimension index dim.\n",
        "\n",
        "torch.cat(tensors, dim=0): Concatenates the input tensors along an existing dimension with the given dimension index dim.\n",
        "\n",
        "Vertical stack (vstack) and horizontal stack (hstack) are common operations in linear algebra and matrix operations. In PyTorch, we can use torch.cat() function to perform these operations.\n",
        "\n",
        "torch.cat(tensors, dim=0): Concatenates the input tensors along the specified dimension dim. When dim=0, torch.cat() performs a vertical stack or a row-wise concatenation of tensors. That is, it concatenates the tensors along the rows or vertically, effectively increasing the number of rows in the output tensor.\n",
        "\n",
        "torch.cat(tensors, dim=1): Concatenates the input tensors along the specified dimension dim. When dim=1, torch.cat() performs a horizontal stack or a column-wise concatenation of tensors. That is, it concatenates the tensors along the columns or horizontally, effectively increasing the number of columns in the output tensor."
      ],
      "metadata": {
        "id": "F5JrVmvJCVEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_catstack = torch.cat((x,x), dim=0)\n",
        "x_catstack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0Pvdck_GXYi",
        "outputId": "f2a7055e-3810-4ef9-8ff9-70c0a6ea2e93"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9., 5., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_vstack = torch.vstack((x,x))\n",
        "x_vstack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgNl6DA4HGjJ",
        "outputId": "c070a01f-f7eb-4f8e-a2fe-0694d5ce156f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_hstack = torch.hstack((x,x))\n",
        "x_hstack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnDCgTIfHppo",
        "outputId": "36f05425-079d-41d2-cfb3-592b81fe0387"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5., 2., 3., 4., 5., 6., 7., 8., 9., 5., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze() - removes all single dimensions from the tensor specified\n",
        "\n",
        "x=torch.rand(1,1,1)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjdVPow2qpOj",
        "outputId": "4449a8dc-5c5f-4f3a-9026-d0a43db5564c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.8011]]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, x.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2qmjj9Rt_-w",
        "outputId": "30a44b0f-5b74-4363-9c09-3158bc01b5eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1, 1]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_squeezed = x.squeeze()\n",
        "x_squeezed,  x.squeeze().shape, x.squeeze().ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OrK12uEuG-o",
        "outputId": "6b7ce710-18fb-4172-eda5-7ae50d827e0b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.8011), torch.Size([]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze() - adds a single dimension to the specified tensor at a specific dim (dimension)\n",
        "\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Adding an extra dimension with unsqueezed()\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX-QDQQlzOAR",
        "outputId": "63488a84-8a34-460f-b425-1cebb379b5ff"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous target: 0.8010972738265991\n",
            "Previous shape: torch.Size([])\n",
            "\n",
            "New tensor: tensor([0.8011])\n",
            "New shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order of axes values with torch.permute(input, dims), returns a view so values in the\n",
        "# permuted tensor will be the same as the original tensor and if you change the values  in the viewl, it will change the values of the original\n",
        "\n",
        "# Create tensor with specific shape\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg04ksevzOfF",
        "outputId": "8039db99-f102-4c0b-c4e7-1a3da144cb9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If change the value in a the permuted tensor or original tensor , it will effect the other as permuted tensor is a view of the original \n",
        "# sharing the same memory as the orignal one\n",
        "\n",
        "x_original[0,0,0], x_permuted[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zot_6CSDzN5l",
        "outputId": "c662e35b-deaf-4f6e-b890-fb08dc07af1f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.4155), tensor(0.4155))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_original[0,0,0] = 666656666\n",
        "x_original[0,0,0] , x_permuted[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2BwDKjK6J5C",
        "outputId": "5e3a9366-1023-4b3c-8903-a04636d8e786"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(6.6666e+08), tensor(6.6666e+08))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing With PyTorch is similar to indexing with NumPy."
      ],
      "metadata": {
        "id": "_dVB0gZE-c9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a tensor:\n",
        "\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1,3,3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZMeKro9Alwo",
        "outputId": "841e8716-aa21-4ebc-f56f-3e9ddcb20612"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]), torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indexing in tensor:\n",
        "\n",
        "x[0], x[0][1] # or x[0,1] same as x[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOJbdvYkAmIY",
        "outputId": "90fae6ff-9e38-4b4d-cf97-2a2926ed56f4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]), tensor([4, 5, 6]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the most inner bracket (last dimension)\n",
        "\n",
        "x[0][2][2], x[0,2,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZQIOOUfAmip",
        "outputId": "5bf573f6-e9b1-4c90-ea60-9a17c1900e6c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9), tensor(9))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \":\" semi colon is also used to index , basically \"all\" of a target dimension\n",
        "\n",
        "x[:,0] # all of zeroth dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvgrN3JBB3pe",
        "outputId": "1b0262aa-346d-4c17-e6eb-d9fbb53072c8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all values of 0th and 1st dimensions but only index 1 of 2nd dimension\n",
        "\n",
        "x[:,:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vsxm2s90Cd3k",
        "outputId": "097663f0-4fed-4488-df5e-24db55b7789b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
        "x[:, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZI28Z0WDlhQ",
        "outputId": "df87d3fc-fb25-4422-8d36-c707b6f9bb61"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0, 1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR-FhFtIEzPC",
        "outputId": "ca9a13c2-40cc-4c31-90a2-4fa14f98ed0d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
        "x[0, 0, :] # same as x[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlldf9PmE2ZV",
        "outputId": "a7e6faa7-e53b-4693-86ea-1558f1725b2a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,:,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAHlB1cKHExF",
        "outputId": "cfa42b26-cc19-42e0-b426-adb9d54b5841"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3, 6, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### PyTorch tensors & NumPy\n",
        "\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.\n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "\n",
        "* `torch.from_numpy(ndarray)` - NumPy array -> PyTorch tensor.\n",
        "* `torch.Tensor.numpy()` - PyTorch tensor -> NumPy array."
      ],
      "metadata": {
        "id": "0EtrPG20IjxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array) # default datatype of numpy array is float64 while pytorch tensor have float32\n",
        "array, tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-j8RaBxIxCG",
        "outputId": "5ecdbe66-9328-4287-e5ef-dcaef727f77e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the value of array, what will this do tensor ?\n",
        "\n",
        "array = array + 1\n",
        "array, tensor\n",
        "\n",
        "# It will not the change the tensor, so keep in mind that tensor is a different memory representation not same"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-stbqQhKTWc",
        "outputId": "cabe1260-8359-49c9-ac38-c6160d2d1d95"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3., 4., 5., 6., 7., 8., 9.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
        "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5HYXyYFKwzp",
        "outputId": "11a038f3-86cf-441c-9368-afa62c8fdbae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And the same rule applies as above, if you change the original tensor, the new numpy_tensor stays the same.\n",
        "\n",
        "# Change the tensor, keep the array the same\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O53-VGpub9j3",
        "outputId": "a32805c0-08f5-4898-937a-bd955492d124"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducibility (Trying to take random out of random) \n",
        "\n",
        "In neural networks randomness plays a huge rule, \n",
        "\n",
        "but the randomness they create is pseusorandomness that is, because they are designed after all. A computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness\n",
        "\n",
        "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
        "\n",
        "In short:\n",
        "\n",
        "start with random numbers -> tensor operations -> try to make better (again and again and again)\n",
        "\n",
        "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform repeatable experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where reproducibility comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n"
      ],
      "metadata": {
        "id": "pCacpJTDV8NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "# create two random tensors and check if they equal each other( they won't)\n",
        "\n",
        "random_A = torch.rand(3,4)\n",
        "random_B = torch.rand(3,4)\n",
        "\n",
        "print(random_A)\n",
        "print(random_B)\n",
        "print(random_A == random_B) # false on every element\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5r2CAqGXbeo",
        "outputId": "ce7a9423-dbd1-425a-a74a-d8f126f79ca6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2767, 0.6555, 0.0180, 0.9653],\n",
            "        [0.0584, 0.3340, 0.3158, 0.4580],\n",
            "        [0.5731, 0.7214, 0.5321, 0.2895]])\n",
            "tensor([[0.1038, 0.9803, 0.3413, 0.1595],\n",
            "        [0.8328, 0.3649, 0.8308, 0.9911],\n",
            "        [0.3394, 0.7794, 0.6656, 0.7141]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create some random but reproducible tensors, two random tensors with the same values.\n",
        "# That's where torch.manual_seed(seed) comes in, where seed is an integer (like 42 but it could be anything) that flavours the randomness.\n",
        "\n",
        "import random\n",
        "\n",
        "# # Set the random seed\n",
        "RANDOM_SEED=43 \n",
        "torch.manual_seed(seed=RANDOM_SEED)# try changing this to different values and see what happens to the numbers below\n",
        "random_C = torch.rand(3,4)\n",
        "\n",
        "# Have to reset the seed every time a new rand() is called \n",
        "# Without this, tensor_D would be different to tensor_C \n",
        "torch.random.manual_seed(seed=RANDOM_SEED)# try commenting this line out and seeing what happens\n",
        "random_D = torch.rand(3,4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_D}\\n\")\n",
        "print(f\"Does Tensor C equal Tensor D? (anywhere)\")\n",
        "random_C == random_D\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l6uqpdCdZUT",
        "outputId": "bf16a047-2eb4-47c9-a1f5-808a56b6b6f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.4540, 0.1965, 0.9210, 0.3462],\n",
            "        [0.1481, 0.0858, 0.5909, 0.0659],\n",
            "        [0.7476, 0.6253, 0.9392, 0.1338]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.4540, 0.1965, 0.9210, 0.3462],\n",
            "        [0.1481, 0.0858, 0.5909, 0.0659],\n",
            "        [0.7476, 0.6253, 0.9392, 0.1338]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Tensors and PyTorch Objects on the GPUS (and making faster computations)\n",
        "\n",
        "Deep learning algorithms require a lot of numerical operations.\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), \n",
        "which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory (good)\n",
        "\n",
        "Getting a GPU: https://www.learnpytorch.io/00_pytorch_fundamentals/#1-getting-a-gpu \n",
        "\n"
      ],
      "metadata": {
        "id": "-mx_qhu_9cj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E76ihgPSVeG_",
        "outputId": "8c9335f7-4071-4812-8288-81d3267f232f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 21 19:14:03 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    26W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU Access with PyTorch\n",
        "# You can test if PyTorch has access to a GPU using \"torch.cuda.is_available()\" .\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# If the above outputs True, PyTorch can see and use the GPU, if it outputs False, \n",
        "# it can't see the GPU and in that case, you'll have to go back through the installation steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEhON6X4bWZC",
        "outputId": "c8ef2e06-868b-49f1-e4c0-0f4ad2543cc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the above output \"cuda\" it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output \"cpu\", our PyTorch code will stick with the CPU.\n",
        "\n",
        "Note: In PyTorch, it's best practice to write device agnostic code. This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "If you want to do faster computing you can use a GPU but if you want to do much faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using torch.cuda.device_count()."
      ],
      "metadata": {
        "id": "4VFm7UYud1LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up device agnostic Code:\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iC8CYeBOdKmt",
        "outputId": "cc587401-715f-41cc-a95a-098eb5d15a6a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count Number of Devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvV7V6mGdZMo",
        "outputId": "2644b993-9f56-46be-b984-873eb1277fca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Putting tensors ( and models) on the gpu as it results in faster computations\n",
        "\n",
        "# Create tensor (default on CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbxpby6lgXju",
        "outputId": "45f5dd54-5370-4325-eb21-68e001c532b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfEwQiFxhNy4",
        "outputId": "5a727a81-801f-4e00-b5c7-6f573de2fad2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## As Numpy only works on the CPU , so we should move it back it to CPU from GPU :\n",
        "# It will give error otherwise as :\n",
        "\n",
        "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
        "tensor_on_gpu.numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "rZLztoZVhgmO",
        "outputId": "f4121c5c-669e-4502-801f-3cc9bfc918e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-00fdcb7a3cda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtensor_on_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead, copy the tensor back to cpu\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu, tensor_on_gpu # The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFWUPk-2hmOP",
        "outputId": "0f40261e-7148-4b87-d157-b40ebf25779c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2, 3]), tensor([1, 2, 3], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}